---
permalink: /
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
https://iopen.nwpu.edu.cn/info/1329/1171.htm


I am a research assistant at [Shanghai AI Lab](https://www.shlab.org.cn), working with Prof. Dr. [Xuelong Li](https://iopen.nwpu.edu.cn/info/1329/1171.htm). Prior to this, I obtained my **M.S. degree** in Control Science and Engineering from [National University of Defense Technology](https://www.nudt.edu.cn) in June 2023, advised by Prof. Dr. [Xin Xu](https://xueshu.baidu.com/scholarID/CN-B7736SUJ), and my bachelor's degree in Computer Science and Technology from [Sichuan University](https://www.scu.edu.cn).
    

<p>
<strong>Research Areas & Interests:</strong> robotics, computer vision, and deep reinforcement learning. 
</p>   
In particular, I am interested in embodied intelligence with a focus on representation learning for multi-modal perception and long-horizon planning via large language models (LLMs):
+ <font color='green'>Representation learning for multi-modal perception</font> How to learn object-generic tokens for prompts? And how to learn task-driven representations for efficient skill learning?
+ <font color='green'>Hierarchical embodied planning</font> How to define and decide the granularity of skills? How to close the loop between high-level skill sequences and low-level control signals for learning-based skills? And how can we solve the “Hand over” problem of skill sequence?
+ <font color='green'>Hierarchical embodied planning</font> 


Publications
------
[1] **Tang Z**, Shi Y, Xu X. [CSGP: Closed-loop Safe Grasp Planning via Attention-based Deep Reinforcement Learning from Demonstrations](https://Zixin-Tang.github.io/assets/pub/CSGP_Closed-Loop_Safe_Grasp_Planning_via_Attention-Based_Deep_Reinforcement_Learning_From_Demonstrations.pdf)[J]. IEEE Robotics and Automation Letters (**RA-L**), 2023, 8(6): 3158-3165.

[2] Shi Y, **Tang Z**, Cai X, Zhang H, Hu D, Xu X. [SymmetryGrasp: Symmetry-Aware Antipodal Grasp Detection From Single-View 
RGB-D Images](https://Zixin-Tang.github.io/assets/pub/SymmetryGrasp_Symmetry-Aware_Antipodal_Grasp_Detection_From_Single-View_RGB-D_Images.pdf)[J]. IEEE Robotics and Automation Letters (**RA-L**), 2022, 7(4):12235-12242.

[3] Xiao Y, **Tang Z**, Xu X, Zhang X, Shi Y. [A deep Koopman Operator-based Modeling Approach for Long-term Prediction of 
Dynamics with Pixel-level Measurements](https://Zixin-Tang.github.io/assets/pub/CAAI_Trans_on_Intel_Tech-2023-A_deep_Koopman_operator_based_modelling_approach.pdf)[J]. **CAAI** Transactions on Intelligence Technology, 2023.

[4] Lan Y, Ren J, Tang T, Xu X, Shi Y, **Tang Z**. [Efficient Reinforcement Learning with Least-squares Soft Bellman Residual for Robotic Grasping](https://Zixin-Tang.github.io/assets/pub/Efficient_reinforcement_learning_with_least-squares_soft_Bellman_Residual_for_robotic_grasping.pdf)[J]. Robotics and Autonomous Systems (**RAS**), 2023, 164: 104385.

[5] **Tang Z**, Xu X, Shi Y. [Grasp Planning Based on Deep Reinforcement Learning: A Brief Survey](https://Zixin-Tang.github.io/assets/pub/Grasp_Planning_Based_on_Deep_Reinforcement_Learning_A_Brief_Survey.pdf)[C]. China Automation Congress (**CAC**). 2021: 7293-7299.



For more info
------
More info can be found in [my Curriculum Vitae](https://Zixin-Tang.github.io/assets/Zixin Tang-Curriculum Vitae.pdf).
